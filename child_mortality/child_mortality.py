# -*- coding: utf-8 -*-
"""ELECTIVE_2_FINALS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u3QSNFzlEgiuA8tnlyxwyNNKAWj3dpnK
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math 

from google.colab import drive
drive.mount('/content/drive/')

cd 'drive/My Drive/Colab Notebooks'

mf_mortality = pd.read_csv('malefemale(1).csv')
#total_mortality = pd.read_csv('total.csv')
mf_mortality = mf_mortality.drop(columns = ['MyUnknownColumn'], axis = 1)

mf_mortality.head()

#Describe
#Get the sorted Location for Mapping 
pd.options.mode.chained_assignment = None 
bX= mf_mortality.sort_values(['Country']) #Sorted Location Ascending 
#bX = np.asarray(bX)

 #Dictionary for Location but has brackets 
trial = dict()
for i in range(len(bX['Country'].unique())):
    # here define what key is, for example,
    key = bX['Country'].unique()[i]
    # check if key is already present in dict
    if key not in trial:
        trial[key] = []
    # append some value 
    trial[key].append(i)

mf_mortality['Country'] = bX['Country'].map(trial) #Mapping Location

newest = [i[0] for i in mf_mortality['Country']]#removes brackets from location
mf_mortality['Country'] = newest
#trial

gender_to = {
    'Male': 0,
    'Female': 1
}
mf_mortality['Gender'] = mf_mortality['Gender'].map(gender_to)

def get_mean(x, df):
  country =x['Country']
  year = int(x['Year']) -1
  total_mean = df.query(f"Country == {country} and Year == {year}")['Mortality Rate'].mean()
  if str(total_mean)!= 'nan':
    return total_mean
  else:
    return 0

mf_mortality['prev_Mean'] = mf_mortality.apply(lambda x: get_mean(x, mf_mortality), axis= 1)

def get_ymean(x, df):
  year = x['Year']

  year_mean = df.query(f"Year == {year}")['Mortality Rate'].mean()
  return year_mean

mf_mortality['year_mean'] = mf_mortality.apply(lambda x: get_ymean(x, mf_mortality), axis= 1)

for column in non_zero:
    mf_mortality[column] = mf_mortality[column].replace(0,np.NaN)
    mean = int(mf_mortality[column].mean(skipna = True))
    mf_mortality[column] = mf_mortality[column].replace(np.NaN, mean)
    print([column])

mf_mortality.head(3000)

trial

from scipy.stats import pearsonr

def check_corr(df, x):
  cor1, _ = pearsonr(df['Country'], df[x])
  cor2, _ = pearsonr(df['Year'], df[x])
  cor3, _ = pearsonr(df['Gender'], df[x])
  cor4, _ = pearsonr(df['Child Mortality(1 to 4)'], df[x])
  cor5, _ = pearsonr(df['Total Population'], df[x])
  cor6, _ = pearsonr(df['prev_Mean'], df[x])
  cor8, _ = pearsonr(df['year_mean'], df[x])
  cor9, _ = pearsonr(df['Mortality Rate'], df[x])
  print(x)
  print('Country Pearsons correlation: %.3f' % cor1)
  print('Year Pearsons correlation: %.3f' % cor2)
  print('Gender Pearsons correlation: %.3f' % cor3)
  print('Total Population Pearsons correlation: %.3f' % cor5)
  print('Previous Mean Pearsons correlation: %.3f' % cor6)
  print('Year Population Mean Pearsons correlation: %.3f' % cor6)
  print('Year Mean Pearsons correlation: %.3f' % cor8)
  print('Child Mortality Pearsons correlation: %.3f\n' % cor4)
  print('Mortality Rate Pearsons correlation: %.3f\n' % cor9)

testing = mf_mortality
testing['Total Population']= testing['Total Population']

check_corr(mf_mortality, 'Country')
check_corr(mf_mortality, 'Year')
check_corr(mf_mortality, 'Gender')
check_corr(mf_mortality, 'Total Population')
check_corr(mf_mortality, 'prev_Mean')
check_corr(mf_mortality, 'year_mean')
check_corr(mf_mortality, 'Child Mortality(1 to 4)')
check_corr(mf_mortality, 'Mortality Rate')

# FOR LINEAR REGRESSION OF MORTALITY RATE
from sklearn.model_selection import train_test_split
X = mf_mortality.drop(columns=['Mortality Rate', 'Total Population', 'year_mean'])
y = mf_mortality['Mortality Rate']
X_trainval, X_test, y_trainval, y_test = train_test_split(X,y,test_size=0.33, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval)

#FOR RANDOM FOREST REGRESSION OF CHILD MORTALITY
train = mf_mortality.query("Year < 2007")
test = mf_mortality.query("Year >= 2007 and Year < 2017")
validation = mf_mortality.query("Year >= 2017")
train['Year'].unique()
print(train.shape)
print(test.shape)
print(validation.shape)

X_train = train.drop(columns =['Child Mortality(1 to 4)'])
y_train = train['Child Mortality(1 to 4)']
X_test = test.drop(columns =['Child Mortality(1 to 4)'])
y_test = test['Child Mortality(1 to 4)']
X_val = validation.drop(columns =['Child Mortality(1 to 4)'])
y_val = validation['Child Mortality(1 to 4)']

X_train = train.drop(columns =['Child Mortality(1 to 4)', 'Year'])
y_train = train['Child Mortality(1 to 4)']
X_test = test.drop(columns =['Child Mortality(1 to 4)', 'Year'])
y_test = test['Child Mortality(1 to 4)']
X_val = validation.drop(columns =['Child Mortality(1 to 4)', 'Year'])
y_val = validation['Child Mortality(1 to 4)']

X_train = train.drop(columns =['Mortality Rate', 'year_mean'])
y_train = train['Mortality Rate']
X_test = test.drop(columns =['Mortality Rate', 'year_mean'])
y_test = test['Mortality Rate']
X_val = validation.drop(columns =['Mortality Rate','year_mean'])
y_val = validation['Mortality Rate']

#CALCULATION
#Create a function with many machine learning models
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

import math

def models(X_train, Y_train, X_test, Y_test, X_val, Y_val):
  
  from sklearn.linear_model import LinearRegression
  lr = LinearRegression()
  lr.fit(X_train, Y_train)
  #Print the training accuracy for each model

  y_test_pred = lr.predict(X_test)
  lr_rmse_test = math.sqrt(mean_squared_error(Y_test, y_test_pred))
  
  y_val_pred = lr.predict(X_val)
  lr_val_rmse_test = math.sqrt(mean_squared_error(Y_val, y_val_pred))
  lr_test_score = r2_score(Y_test, y_test_pred)
  lr_val_score = r2_score(Y_val, y_val_pred)


  from sklearn.ensemble import RandomForestRegressor
  from sklearn.datasets import make_regression
  regr = RandomForestRegressor(max_depth=6, random_state=0, min_samples_leaf = 2)
  print(X_train.shape)
  regr.fit(X_train, Y_train)

  fr_y_pred = regr.predict(X_test)
  fr_test_rmse_test = math.sqrt(mean_squared_error(Y_test, fr_y_pred))


  fr_y_val = regr.predict(X_val)
  fr_val_rmse_test = math.sqrt(mean_squared_error(Y_val, fr_y_val))
  val_score = regr.score(X_val, Y_val)

  val_score = r2_score(Y_val,fr_y_val)
  test_score = r2_score(Y_test,fr_y_pred)

  #Linear Regression
  print("Linear Regression")
  print("Model Prediction: ",lr_rmse_test, lr_test_score)
  print("Validation: ",lr_val_rmse_test, lr_val_score)

  #print("Random Forest")
  #print("Model Prediction: ",fr_test_rmse_test, test_score)
  #print("Validation: ",fr_val_rmse_test,val_score)

  #Generalized Linear Regression

  #return log, knn, svc_lin, svc_rbf, gauss, tree, forest
  #return lr

model = models(X_train, y_train, X_test, y_test, X_val, y_val)

from sklearn.neighbors import KNeighborsClassifier
import numpy as np

val_scores =[]
neighbors = np.arange(1, 15, 2)
for i in neighbors:
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(X_train, y_train)
  val_scores.append(knn.score(X_val, y_val))
  print("Best validation score {:.3f}".format(np.max(val_scores)))
  best_n_neighbors = neighbors[np.argmax(val_scores)]
  print("Best n_neighbors:", best_n_neighbors) 
  
  knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)
  knn.fit(X_trainval,y_trainval)
  print("Test-set score {:.3f}".format(knn.score(X_test, y_test)))
  print()

from sklearn.metrics import confusion_matrix

for i in range (len(model)):
  cm = confusion_matrix(y_test, model[i].predict(X_test))

  #Extract TN, FP, FN, TP
  TN, FP, FN, TP = cm.ravel()
  test_score = (TP + TN) / (TP + TN + FN + FP)
  print(cm)
  print('Model[{}] Testing Accuracy = "{}"'.format(i, test_score ))
  print()